defaults:
 - datamodule: defaulthubert
lightning_module:
  _target_: gslm.u2s.hifigan.lightning_module.HiFiGANEmbeddingXvectorLightningModule
  _recursive_: false
  cfg:
    sample_rate: 22_050
    preprocess:
      stft:
        n_fft: 1024
        win_length: 1024
        hop_length: 256
        power: 1
        center: true
      mel:
        n_mels: 80
        sample_rate: 22_050
        f_min: 0
        f_max: 8000
        n_stft: 513
        norm: "slaney"
        mel_scale: "slaney"
    model:
      generator:
        num_tokens: 1000
        num_input_channels: 512
        upsample_rates: [7,7,3,3]
        upsample_initial_channel: 512
        upsample_kernel_sizes: [15,15,7,7]
        resblock_dilation_sizes: [[1,3,5], [1,3,5], [1,3,5]]
        resblock_kernel_sizes: [3,7,11]
        resblock: "1"
        xvector_dim: 512

      optim:
        opt_g:
          _target_: torch.optim.AdamW
          lr: 0.0002
          betas: [0.8,0.99]
        opt_d:
          _target_: torch.optim.AdamW
          lr: 0.0002
          betas: [0.8,0.99]
        scheduler_g:
          _target_: torch.optim.lr_scheduler.ExponentialLR
          gamma: 0.999998
        scheduler_d:
          _target_: torch.optim.lr_scheduler.ExponentialLR
          gamma: 0.999998
      adversarial_start_step: -1

      loss:
        recons_coef: 45
        fm_mpd_coef: 1
        fm_msd_coef: 1
        g_mpd_coef: 1
        g_msd_coef: 1
      logging_wav_samples: 10
trainer:
  _target_: lightning.Trainer
  accelerator: "gpu"
  strategy: ddp_find_unused_parameters_true
  precision: 32
  check_val_every_n_epoch: 1
  max_epochs: 3300
logger:
  - _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: "tb_logs"
  - _target_: lightning.pytorch.loggers.WandbLogger
    project: "u2s"
    log_model: "all"
ckpt_path:
